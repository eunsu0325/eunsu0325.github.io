---
layout: single
title:  "LSFM: Light Style and Feature Matching for Efficient Cross-Domain Palmprint Recognition 논문 Review "
categories: Review
tags: [review]
comments: true
author_profile: false
toc: true   
math: true
sidebar:        
    nav: "counts"
---

# 서론

오늘은 LSFM (Light Style and Feature Matching) 논문을 리뷰해보려고 한다.
저번 포스팅에서는 CCNet을 소개하면서 손바닥 인식 시스템을 구현해봤는데, 실제 라즈베리파이 카메라 모듈로 손바닥 사진을 찍어서 적용해보니 도메인 쉬프트(Domain Shift) 문제가
발생했다.

그래서 더 좋은 방법이 없을까 고민하다가, 라벨이 없는 타겟 도메인 데이터에도 잘 작동할 수 있는 '크로스 도메인 인식(Cross-Domain Recognition)' 관련 논문들을 찾게 
되었고, 그 중에서도 LSFM 논문이 인상적이라 이번에 소개하게 되었다.

![image](/images/first/LSFM_Abstract.png)

> 딥 뉴럴 네트워크(DNN)의 뛰어난 특징 추출 능력은 손바닥 인식(palmprint recognition) 기술을 크게 발전시켰다. 하지만 DNN은 일반적으로 학습(training)과 테스트
> (testing) 데이터가 동일한 분포에서 나와야 좋은 성능을 내기 때문에, 실제 응용에서 제약이 따른다. 게다가 기존의 비지도 도메인 적응(unsupervised domain 
> adaptation) 방법들은 높은 정확도와 효율성을 동시에 달성하는 데 어려움을 겪고 있다.
>
> 이러한 문제를 해결하기 위해, 우리는 LSFM(Light Style and Feature Matching)이라는 효율적인 방법을 제안한다. 이 방법은 적은 자원으로도 크로스 도메인 손바닥 인식 
> 성능을 향상시킨다. 구체적으로, 우리는 픽셀 수준에서의 도메인 차이를 줄이기 위해 효율적인 스타일 전이 모델을 개발하고, 
> 이어서 **여러 태스크 특화 계층(task-specific layer)**에서 고차원 특징 공간 상의 특성(feature)을 정렬하여 도메인 차이를 추가로 감소시킨다.
>
> 마지막으로, 우리는 두 개의 공개 멀티 도메인 손바닥 데이터셋을 활용한 광범위한 실험을 통해 LSFM의 효과를 검증한다. 그 결과, LSFM은 기존 대비 훨씬 적은 자원 소모로도 더 
> 우수한 성능을 달성하였으며, 평균 정확도는 94.87%, 평균 Equal Error Rate(EER)은 **1.46%**로 낮추는 동시에, 자원 소모를 80% 이상 절감하는 성과를 보였다.

초록 부분이다./
연산 자원은 최소화하면서도 도메인 간 성능 차이를 극복해야하는 라즈베리파이와 같은 엣지 디바이스 환경에 딱 적합하였다.

# 📚 논문 리뷰: LSFM — 효율적인 크로스 도메인 손바닥 인식을 위한 경량 스타일 및 특징 정렬 기법

## ✨ 들어가며

손바닥 인식(Palmprint recognition)은 최근 다양한 보안 및 인증 분야에서 각광받는 생체 인식 방식 중 하나입니다.  
그 이유는 다음과 같습니다:

- 촬영이 간편하고 정확도도 높음  
- 비접촉식으로 **위생적**  
- **위·변조가 어려움**

하지만 실제로 손바닥 인식을 시스템에 적용하려고 하면, 여러 가지 난관이 존재합니다.

---

## 문제점: 도메인 쉬프트와 자원 제약

###  도메인 쉬프트 문제
딥러닝 모델은 **학습에 사용된 환경(도메인)**과 실제 적용 환경이 다르면 성능이 급격히 하락합니다.  
예를 들어, 조명, 카메라, 사용자 손 위치가 조금만 달라도 성능이 떨어지죠. 이를 **도메인 쉬프트(domain shift)**라고 부릅니다.

###  라벨링 비용
라벨이 없는 새로운 환경(도메인)에 맞춰 모델을 fine-tuning하려면,
많은 양의 **라벨링된 손바닥 이미지**가 필요합니다. 이는 **비용과 시간**이 매우 큽니다.

###  자원 문제
많은 기존 연구들이 리소스를 충분히 사용할 수 있는 환경에 초점을 맞추다 보니,  
**라즈베리파이, Jetson Nano** 같은 **엣지 디바이스**에는 적용이 어려운 무거운 모델이 많았습니다.

---

##  기존 접근 방식: UDA (Unsupervised Domain Adaptation)

라벨 없는 환경에 적응하기 위한 다양한 **비지도 도메인 적응 (UDA)** 기법들이 제안되어 왔습니다.  
크게 세 가지 방식으로 나눌 수 있습니다:

###  1. 분산 기반 방법
- 도메인 간의 **통계적 분포 차이(MMD, KL 등)**를 줄임
- 장점: 도메인 불변 특징 생성 가능  
- 한계: 여러 층이 아닌 단일 계층 정렬로는 부족함

###  2. 적대적 학습 기반 방법 (Adversarial)
- GAN을 활용해 도메인 정렬
- 학습이 불안정하고 최적화가 어려움

###  3. 의사 라벨링 기반 방법
- 예측값을 라벨처럼 사용하여 재학습
- 노이즈 있는 의사 라벨로 인해 성능 저하 가능성 존재

> 공통 한계:  
> 대부분 **리소스 비용이 높고**, **하나의 도메인 쌍에만 최적화**되어 있음.  
> 다수의 도메인을 다루거나, 엣지 디바이스에 올리기에는 **비효율적**입니다.

---

##  LSFM의 핵심 제안: 두 가지 과제 해결

이 논문은 손바닥 인식에서 도메인 쉬프트를 해결하면서도 **리소스 소모를 최소화**할 수 있는 기법인  
**LSFM (Light Style and Feature Matching)**을 제안합니다.

###  도전 과제 1:  
**"경량화된 스타일 전이 모델을 통해 픽셀 수준 정렬을 구현하라!"**

기존 스타일 전이 모델(예: StarGAN, CycleGAN 등)은 도메인 수가 많아질수록  
`m(m-1)`개의 Generator를 요구하거나 너무 무겁습니다.  
LSFM은 이를 해결하기 위해 **LightStarGAN**이라는 경량 unified 모델을 도입합니다.

→ 하나의 Generator로 다양한 도메인 간 이미지 스타일 전이가 가능하며,  
→ 학습과 추론 모두에서 **자원 소비가 매우 낮습니다.**

---

### 도전 과제 2:  
**"다계층에서 도메인 불변 특징을 효과적으로 학습하라!"**

많은 기존 방식은 마지막 특징 층만 정렬하거나, 분포를 강제로 같게 만들려고 합니다.  
하지만 실제로 도메인 간 분포는 **자연스럽게 다를 수밖에 없습니다.**  
억지로 맞추려 할수록 오히려 성능이 떨어질 수 있습니다.

→ LSFM은 이를 해결하기 위해,  
여러 개의 **task-specific layer**에 걸쳐 특징 정렬(MK-MMD)을 수행합니다.

---

## LSFM의 핵심 구성 요약

### 1. LightStarGAN
- 다양한 도메인 간 이미지 스타일 전이를 수행하는 경량 스타일 전이 모델
- `m-1` 개의 Generator가 필요했던 구조를 **하나의 unified 모델**로 통합
- 학습과 추론 단계 모두에서 **자원 효율성** 확보

### 2. Multi-level Feature Matching
- 다양한 특화 계층의 feature를 MK-MMD를 이용해 정렬
- 도메인 간 분포 차이를 점진적으로 줄임  
- **단일 계층 정렬보다 훨씬 안정적이고 효과적**

---

## 실험 결과 및 기여 정리

### 실험 설정
- PolyU & CASIA 공개 멀티 도메인 손바닥 데이터셋 사용

### 주요 성과
- 평균 정확도 **94.87%**  
- Equal Error Rate (EER) **1.46%**  
- **자원 사용량 80% 이상 절감**

---

## 논문의 주요 기여

1. **경량 크로스 도메인 손바닥 인식 프레임워크 LSFM 제안**  
   → 실제 적용 가능한 수준의 효율성 확보

2. **LightStarGAN 도입**  
   → 하나의 Generator로 다양한 도메인 전이 수행 가능

3. **다계층 MK-MMD 기반 특징 정렬 적용**  
   → 더 강건한 도메인 적응

4. **실험을 통해 기존 방법보다 더 우수한 성능과 효율성 입증**

---

# LSFM의 작동 방식 (III. METHOD)

## A. 문제 정의 및 수식 설명

논문에서는 손바닥 인식에서의 UDA(Unsupervised Domain Adaptation) 문제를 다음 **두 단계**로 나누어 설명합니다:

### 1단계: 라벨이 있는 소스 데이터로 모델 학습

먼저, 소스 도메인에서 라벨이 붙은 손바닥 이미지를 사용하여 모델을 학습합니다.
이 데이터셋은 다음과 같이 표현됩니다:

```
DS = {(pᵢˢ, yᵢˢ)} for i = 1 to Nₛ
```

여기서:

* `pᵢˢ`: 소스 도메인의 손바닥 이미지
* `yᵢˢ`: 해당 손바닥의 클래스 라벨
* `Nₛ`: 소스 도메인의 샘플 개수

모델은 특징 추출기 `F_Eˢ`와 분류기 `H_S`로 구성되어 있고,
이들을 통해 학습된 함수 `F_S = H_S ∘ F_Eˢ`는
입력된 손바닥 이미지를 **K개의 클래스** 중 하나로 분류합니다.

#### 사용되는 손실 함수 (Loss Function)

```
L_cls = (1 / Nₛ) * Σ [L_CE(H_S(F_Eˢ(pᵢˢ)), yᵢˢ)]
```

여기서:

* `L_CE`: Cross-Entropy 손실 함수
* `θ_{F_Eˢ}`와 `θ_{H_S}`: 각각 특징 추출기와 분류기의 파라미터

이 손실 함수는 소스 도메인에서 손바닥을 정확히 분류하도록 모델을 학습시키는 역할을 합니다.

---

### 2단계: 라벨이 없는 타겟 데이터에 적응

이제 모델을 **라벨이 없는 타겟 도메인**으로 적응시켜야 합니다.
타겟 데이터셋은 다음과 같이 표현됩니다:

```
DT = {(pᵢᵗ)} for i = 1 to N_T
```

여기서:

* `pᵢᵗ`: 타겟 도메인의 손바닥 이미지
* `N_T`: 타겟 도메인의 샘플 개수
* 라벨 `y`는 없습니다 

타겟 도메인 `P_T`는 소스 도메인과 유사하지만,
**조명, 각도, 센서 차이 등**으로 인해 분포가 다릅니다.
그러나 **클래스 라벨의 종류(Y\_T)는 동일(Y\_T = Y\_S)** 하다고 가정합니다.

---

## 최종 목표

> **라벨이 있는 소스 도메인 데이터 `D_S`와, 라벨 없는 타겟 도메인 데이터 `D_T`를 함께 활용하여,
> 타겟 도메인에서의 모델 성능을 향상시키는 것!**

즉, 학습은 소스 도메인에서 시작되지만,
**실제 성능은 타겟 도메인에서 좋아야** UDA가 성공한 것입니다.

---

이 구조를 이해하면, LSFM이 왜 스타일 전이와 특징 정렬을 동시에 사용하는지 납득이 갑니다.
이제 다음 섹션에서 이 두 전략이 **어떻게 구현되는지** 이어서 설명하겠습니다!

## B. LSFM 아키텍처 개요

기존의 딥러닝 기반 크로스 도메인 손바닥 인식 연구들은 실제 응용에 중요한 요소인 \*\*자원 제약(resource constraints)\*\*을 종종 간과해왔습니다. 하지만 손바닥 인식 시스템은 보통 **리소스가 제한된 하드웨어(엣지 디바이스)** 위에 배치되기 때문에, 모델은 반드시 **경량성과 효율성**을 우선시해야 합니다.

이를 해결하기 위해 LSFM은 실제 응용을 고려한 효율적인 UDA 방법을 제안합니다. 이 시스템은 Fig. 2와 같이 구성되어 있으며, 다음과 같은 방식으로 작동합니다.

### 스타일 코드 기반 가짜 타겟 이미지 생성

* LSFM의 Generator는 도메인 라벨 `d`를 기반으로 한 \*\*스타일 코드 `sc`\*\*를 사용하여 **다양한 도메인에 해당하는 가짜 손바닥 이미지**를 생성합니다.
* 스타일 코드는 다음 두 가지 방식 중 하나로 생성됩니다:

  * \*\*무작위 노이즈 벡터 `z`\*\*를 mapping network `M`에 통과시켜 생성
  * \*\*스타일 인코더 `SE`\*\*로 참조 이미지를 인코딩하여 추출

이렇게 생성된 스타일을 통해 \*\*픽셀 레벨 도메인 차이(pix-level shift)\*\*를 줄일 수 있습니다.

### 특징 정렬: MK-MMD 기반 다계층 정렬

* 스타일 전이 이후, 각 도메인에 특화된 layer들에서의 feature들을 **Reproducing Kernel Hilbert Space (RKHS)** 상에서 정렬합니다.
* 특히, 타겟 이미지의 feature가 가짜 타겟 이미지와 유사하도록 학습됩니다.
* 이를 위해 \*\*Multiple Kernel Maximum Mean Discrepancy (MK-MMD)\*\*를 사용하여 분포 차이를 줄입니다.
* 스타일 전이가 선행되었기 때문에 이 정렬 과정의 효과도 더 커집니다.

### 핵심 장점 정리

* LightStarGAN 구조를 통해 **모델 수, 파라미터 수, 계산량을 크게 줄임**
* 다양한 도메인 쌍마다 모델을 따로 학습할 필요 없음
* 소스/타겟 이미지를 모두 활용하지만 **라벨 없이 작동하는 순수 비지도 방법**

> 요약: LSFM은 스타일 전이를 통해 픽셀 수준 차이를 줄이고, MK-MMD 기반 정렬로 특징 공간에서의 도메인 차이까지 완화함으로써, **리소스 효율성과 정확도 모두를 잡은 구조**입니다.

---

## Fig. 2로 보는 전체 LSFM 구조 요약

![image](/images/first/lsfm_아키텍쳐.png)

### 전체 흐름 정리

1. **Source 이미지 → Generator → Fake Target 이미지 생성**

   * 소스 이미지를 `G_{S→T}`로 변환하여 타겟 스타일의 이미지 생성
   * GAN Loss를 통해 진짜 타겟 이미지와의 분포 정렬

2. **Fake Target 이미지 → Target Feature Extractor에 입력**

   * Fake Target을 통해 `F_E_T`를 학습시킴 (초기값은 소스 모델로부터 복사)

3. **Target 이미지도 함께 `F_E_T`로 특징 추출**

   * 라벨은 없지만 분포상 차이(MK-MMD)를 정렬해줌

4. **Classifier는 Multi-FCs로 구성**

   * 특징 추출 후 여러 Fully Connected Layer로 구성된 분류기(`H_T`)에 입력

5. **MK-MMD로 Fake Target ↔ Target 간 분포를 정렬**

   * 각 계층의 feature를 정렬하여 더욱 정밀한 적응 수행

6. **Source 이미지 경로는 기존 Cross-Entropy 기반으로 학습**

### 구성 요소 키워드 요약

| 구성 요소        | 설명                                    |
| ------------ | ------------------------------------- |
| `G_{S→T}`    | Source → Target 이미지 생성기 (스타일 전이)      |
| `F_E_T`      | Target feature extractor (초기화: 소스 기반) |
| `H_S`, `H_T` | 분류기, Multi-FCs 구조                     |
| `M`          | MK-MMD 정렬 손실 (여러 계층에 적용)              |
| `D`          | GAN의 Discriminator 역할                 |

---

# C. Style Matching (스타일 매칭)

## 🧩 1. 목적: 도메인 간 간극(domain gap) 해소

손바닥 인식 시스템은 센서/조명/채널 변화에 민감하여,  
**같은 사람의 손이라도 스타일이 다르게 나타날 수 있음** (도메인 쉬프트 문제).

이를 해결하기 위한 전략:

> **Style Transfer Model**을 이용해  
> 소스 도메인 손바닥 이미지를 타겟 도메인 스타일로 변환한  
> **Fake Target Image** 생성  
> → 이 이미지는 원본과 **동일한 ID 정보(정체성)** 를 가짐  
> → 라벨 정보를 공유하여 **supervised 학습에 활용 가능**

---

## 🔁 2. Supervised Fine-tuning with Fake Target Images

- Fake Target 이미지는 **소스 이미지와 동일한 라벨**을 유지
- 따라서 타겟 도메인에서도 **라벨 기반의 supervised 학습**이 가능
- 이는 도메인 적응 성능 향상에 매우 효과적임

---

## ❗ 3. 기존 방식의 비효율성: One-to-One 방식

[12], [14]의 기존 연구들은 **one-to-one 변환** 구조를 사용:

- 각 도메인 쌍마다 → 2개의 모델 필요 (A→B, B→A)

### 📌 예시: PolyU Multi-Spectral Palmprint Dataset
- 총 4개 도메인 존재  
- 가능한 도메인 쌍 수:

  $$
  \binom{4}{2} = 6
  $$

- 각 쌍마다 양방향 변환이 필요하므로:

  $$
  6 \times 2 = 12 \text{개의 Generator 필요}
  $$

---

## 🧮 4. 총 Generator 수 공식

도메인 수를 $m$이라 할 때, 전체 스타일 전이 모델의 개수 $N_{ST}$는 다음과 같음:

$$
N_{ST} = 2 \times \binom{m}{2} = m(m - 1)
$$

- $\binom{m}{2}$: 도메인 간 쌍의 수 (순서 무관)
- $2$: A→B, B→A 양방향 고려

> 도메인 수가 증가할수록 모델 수가 **기하급수적으로 증가**  
> → 리소스 낭비, 비효율, 유지보수 어려움

---

## 💥 5. 기존 방식의 문제점 정리

- 도메인 수 증가 → Generator 수 급증
- 모든 쌍마다 **별도의 Generator** 필요
- 기존 Generator 구조:
  - ResNet block [20]  
  - Transformer block [65]  
  → 연산 비용 높고, 메모리 사용 많음
- 실제 시스템(embedded, mobile 등)에서 **적용 어려움**

---

## 💡 6. LSFM의 해결책: Unified Style Transfer


![image](/images/first/lsfm_Transfer_Schema.png)
> 📘 Fig. 3(b): 하나의 Generator로 모든 도메인 간 스타일 전환

스타일 전이 구조 비교: One-to-One vs Unified Transfer

이 그림은 LSFM 논문에서 사용된 두 가지 **도메인 간 스타일 전이 방식**을 비교합니다.

## 🧩 (a) One-to-One Transfer Scheme

이 방식은 가장 **직관적이고 전통적인 스타일 전이 구조**입니다.

### 구조 설명
- **도메인 1 → 도메인 2** 전환을 위한 Generator: $G_{1 \rightarrow 2}$
- **도메인 2 → 도메인 1** 전환을 위한 Generator: $G_{2 \rightarrow 1}$

즉, **도메인 쌍마다 서로 다른 변환기를 따로 만들어야 합니다.**

### 예를 들어,
- 3개 도메인이 있으면?
  - 도메인 1 ↔ 도메인 2
  - 도메인 1 ↔ 도메인 3
  - 도메인 2 ↔ 도메인 3  
  → 총 6개의 generator가 필요합니다.

> 🔺 장점: 구조가 단순하고 각 도메인 쌍에 최적화된 전이 가능  
> 🔻 단점: **도메인 수가 많아질수록 generator 수도 급증 → 매우 비효율적**

---

## 🔁 (b) Unified Transfer Scheme

이 구조는 LSFM 논문에서 채택한 방식으로,  
**하나의 통합된 Generator $G$만으로 모든 도메인 간 변환을 처리**합니다.

### 구조 설명
- **하나의 generator $G$** 사용
- **Style Codes**를 입력으로 사용하여 원하는 도메인의 스타일을 결정
- 도메인 간 전환은 style code만 바꾸면 됨!

예:
- 도메인 1 → 도메인 3  
  → 입력 이미지 + 도메인 3의 스타일 코드 → Generator 통과  
- 도메인 2 → 도메인 1  
  → 입력 이미지 + 도메인 1의 스타일 코드 → Generator 통과

> 🔹 장점:  
> - 도메인 수와 관계없이 **Generator는 1개만 사용**  
> - 학습 및 유지 관리가 쉬움  
> - 실제 환경에 더 적합 (특히 많은 도메인이 존재하는 경우)

> 🔻 단점:  
> - 하나의 모델이 여러 도메인을 모두 커버해야 하므로  
>   학습이 조금 더 어려울 수 있음  
> - style code의 품질이 성능에 큰 영향을 미침

---

## ⚖️ 구조 비교 요약

| 항목 | One-to-One | Unified Transfer |
|------|-------------|-------------------|
| Generator 개수 | $O(m^2)$ | 1 |
| 확장성 | 낮음 | 매우 높음 |
| 관리 복잡도 | 높음 | 낮음 |
| 학습 난이도 | 낮음 | 중간 |
| 적용 예시 | StarGAN v1 | StarGAN v2 / LSFM |

---

### 핵심 개념
- 입력: 소스 이미지 $$p^S$$, 스타일 코드 $$sc$$
- 출력: 가짜 타겟 이미지 $$p^{FT}$$

$$
p^{FT} = G(p^S, sc)
$$

- 다양한 도메인 스타일을 하나의 모델이 다룰 수 있음
- 도메인 수가 많아져도 Generator는 **1개만 유지**

---

## ⚙️ 7. Unified Generator 구조

| 구성 요소       | 설명 |
|----------------|------|
| Light Encoder  | 소스 이미지에서 content feature 추출 |
| Light Decoder  | style code를 결합해 이미지 복원 |
| ShuffleNetV2   | 경량화된 CNN 구조 |
| Shortcuts [69] | Encoder와 Decoder 사이 skip connection |

> 기존의 ResNet/Transformer 대신, **가벼운 구조** 사용으로 리소스 절감

---

## 🔁 8. Down/Up Sampling 전략


![image](/images/first/lsfm_flamework.png)
> 📘 Fig. 4(a)
이 그림은 LSFM 논문에서 제안된 전체 스타일 전이 시스템,  
즉 **LightStarGAN의 Generator와 Discriminator 구조**, 그리고  
**Decoder 내부 구성 (LightDecoderLayer)** 를 보여줍니다.

## 🧱 (a) LightStarGAN의 Generator 구조

### 📥 입력: Source Images
- 소스 도메인의 손바닥 이미지 입력
- 예: 근적외선, 백색광, 적외선 등 다양한 촬영 조건의 이미지

---

### 🧠 인코더 부분: LightEncoderLayer1 ~ LightEncoderLayer6

- 총 6단계로 구성된 경량화된 인코더 구조
- 앞의 4개 층은 각각 2배로 다운샘플링 (`↓2`)
  - 이미지 크기를 줄이면서 특징을 압축
- 뒤의 2개 층 (Layer5, Layer6)은 다운샘플링 없이 정보만 정제
- 내부적으로는 `ShuffleNetV2` 기반의 경량 연산을 사용함

---

### 🎨 스타일 코드 생성: Target Style Codes

- 어떤 스타일로 변환할지 알려주는 벡터
- 아래 2가지 방법으로 생성:

1. **Mapping Network**  
   - 무작위 벡터 $Z$ + 도메인 라벨 → style code 생성

2. **Style Encoder**  
   - 참조 이미지(Ref Images) → 스타일 특징 추출하여 style code 생성

→ 둘 중 하나를 선택하여 Generator에 style 정보를 제공합니다.

---

### 🖌️ 디코더 부분: LightDecoderLayer1 ~ LightDecoderLayer6

- 총 6단계 디코더 구조
- 앞의 4개 층은 각각 2배 업샘플링 (`↑2`)
  - 이미지 해상도를 다시 키움
- 뒤의 2개 층은 해상도 유지하며 이미지 정제
- Encoder와 Decoder 사이에는 Skip Connection이 존재
  - 정보 손실을 방지하며 세부 정보 유지

---

### 🖼️ 출력: Fake Target Images

- 타겟 도메인의 스타일을 입힌 가짜 손바닥 이미지 생성
- 정체성은 소스 이미지와 같고, 외형은 타겟 도메인과 유사함

---

### 🔍 판별기: Discriminator

- 생성된 이미지가 진짜(real)인지 가짜(fake)인지 판단
- 각 도메인마다 따로 존재
- "R/F"는 Real / Fake 판단 결과를 의미함

---

## 🔬 (b) LightDecoderLayer 내부 구성

### 📥 입력
- Features (인코더에서 온 콘텐츠 정보)
- Style Codes (타겟 도메인의 스타일)

---

### 1️⃣ AdaIN (Adaptive Instance Normalization)

- 스타일 코드를 기반으로 특징(feature)의 통계값을 조정
- 핵심 스타일 변환 모듈

---

### 2️⃣ Upsampling

- 이미지 해상도를 2배 키움
- LightDecoderLayer5~6는 이 단계를 생략함 (그대로 유지)

---

### 3️⃣ Channel Split

- 특징 맵을 2개로 나눔
  - 좌측: Depthwise Conv 흐름
  - 우측: 일반 Conv 흐름

---

### 4️⃣ 두 분기 처리

#### 좌측 분기:
- $3 \times 3$ Depthwise Conv → $1 \times 1$ Conv

#### 우측 분기:
- $1 \times 1$ Conv → $3 \times 3$ Depthwise Conv → $1 \times 1$ Conv

→ 이렇게 두 흐름을 분리하여 처리한 뒤 합칩니다.

---

### 5️⃣ Concat + Channel Shuffle

- 두 분기를 Concatenate (합치기)
- Channel Shuffle을 통해 채널을 섞음
  → 표현 다양성 증가 + 정보 혼합

---

### 📌 참고: LightDecoder → LightEncoder로 변환 가능

- LightDecoderLayer에서 **Style Code / AdaIN / Upsampling**을 제거하면
  → 동일한 구조로 LightEncoderLayer로도 활용 가능함

- DWConv stride:
  - Layer1~4: stride = 2 (다운/업 샘플링 포함)
  - Layer5~6: stride = 1 (샘플링 없음)

---

## ✅ 전체 요약

| 구성 요소          | 설명 |
|-------------------|------|
| Source Image      | 스타일 변환 대상 원본 손바닥 이미지 |
| LightEncoder      | 특징 추출 및 압축 |
| Target Style Code | 목표 도메인의 스타일 표현 |
| LightDecoder      | 특징 복원 + 스타일 적용 |
| AdaIN             | 스타일 정보와 콘텐츠 정보를 혼합 |
| Discriminator     | 생성된 이미지가 진짜 같은지 판별 |
| ShuffleNet 구조   | 전체 경량화 설계의 핵심 |

---

## 📝 결론

이 구조는 StarGAN의 기본 개념을 바탕으로  
**모든 도메인 간 스타일 전이를 하나의 Generator로 처리**하고,  
**모바일/임베디드 환경에서도 구동 가능하도록 경량화**된 GAN 구조입니다.

특히 LightDecoderLayer는 단순히 복원만 하는 것이 아니라  
**스타일 변환, 효율적인 병렬 처리, 정보 유지**까지 고려한 최적 설계입니다.

### 비교 요약

| 샘플링 수 | 장점                 | 단점                    |
|-----------|----------------------|-------------------------|
| 적게 사용 | 공간 정보 손실 적음  | Feature map 크기 증가, 연산량 증가 |
| 많이 사용 | 연산량, 메모리 절감 | 공간 정보 손실 가능성 증가 |

---

## 📌 9. 용어 정리

- $$p_i^{FT}$$: Generator로부터 생성된 fake target palm image
- $$P_{FT}$$: Fake Target 도메인 전체
- $$\theta_{F_{ET}}, \theta_{H_T}$$: Feature Extractor와 Head의 파라미터

---

## ✅ 요약

LSFM의 Style Matching은 기존의 pair-wise 방식의 비효율성을 극복하고,  
하나의 lightweight generator로 모든 도메인 간 스타일 전환을 수행합니다.  
이로써 **도메인 적응 성능을 향상**시키고 **실제 적용 가능성**을 높이는 데 기여합니다.

# 🧠 LSFM 논문 정리: D. Feature Matching (특징 정렬)

## 📌 왜 Feature Matching이 필요한가?

Palmprint(손바닥 무늬) 인식에서,  
소스 도메인(예: 적외선 센서로 찍은 이미지)과  
타겟 도메인(예: 백색광 센서로 찍은 이미지) 사이에는 **스타일 차이뿐 아니라 특징의 분포 차이**도 있습니다.

> ✅ 스타일(Style)은 픽셀 수준의 외형,  
> ✅ 특징(Feature)은 이미지에서 학습된 의미 있는 정보입니다.

따라서 단순히 이미지의 겉모습만 바꾸는 **스타일 변환만으로는 부족**하고,  
**내부의 의미 있는 정보(특징)도 정렬해야** 성능이 올라갑니다.

---

## 🎯 LSFM의 접근 방식

- 타겟 도메인의 진짜 이미지 $p^T$와
- 스타일만 바꾼 가짜 이미지 $p^{FT}$ (Fake Target Image)

이 둘의 **특징(feature)** 을 비교하여 정렬합니다.

> 💡 둘 다 같은 스타일이므로 정렬이 더 쉽고 효과적!

---

## 📐 핵심 아이디어: MMD (Maximum Mean Discrepancy)

- MMD는 두 데이터 집합의 분포 차이를 정량화하는 수학 도구입니다.
- 딥러닝 모델이 학습한 특징의 분포가  
  소스와 타겟 도메인에서 얼마나 다른지를 측정할 수 있습니다.

---

## 🧾 수식으로 보는 Feature Matching

### 1️⃣ MMD 기본 정의 (식 9)

$$
\mathcal{L}_{\text{MMD}}^{FT-T}(feat^{FT}, feat^T) = 
\left\| \mathbb{E}_{p^{FT}}[\phi(feat^{FT})] - \mathbb{E}_{p^T}[\phi(feat^T)] \right\|^2_{\mathcal{H}_K}
$$

- $$feat = H(FE(p))$$: 이미지에서 추출된 특징
- $$\phi(\cdot)$$: 고차원 공간(RKHS)으로 보내는 함수
- $$\mathcal{H}_K$$: 특징 분포를 비교하는 공간

> 두 도메인의 평균 특징이 얼마나 다른지를 계산합니다.

---

### 2️⃣ 계산 가능한 형태 (식 10)

실제 계산을 위해, 내적을 커널 함수 $k(a, b)$로 바꾸면 다음과 같습니다:

$$
\mathcal{L}_{\text{MMD}}^{FT-T}(feat^{FT}, feat^T) = 
\left\|
\frac{1}{N_S^2} \sum_{i_1=1}^{N_S} \sum_{i_2=1}^{N_S} k(feat^{FT}_{i_1}, feat^{FT}_{i_2}) \\
- \frac{1}{N_S N_T} \sum_{i=1}^{N_S} \sum_{j=1}^{N_T} k(feat^{FT}_i, feat^T_j) \\
- \frac{1}{N_T^2} \sum_{j_1=1}^{N_T} \sum_{j_2=1}^{N_T} k(feat^T_{j_1}, feat^T_{j_2})
\right\|_{\mathcal{H}_K}
$$

- $$N_S$$: 가짜 이미지 수
- $$N_T$$: 진짜 타겟 이미지 수
- $$k(a,b)$$: 두 특징 벡터 간의 유사도

---

## 🔁 다양한 커널을 사용한 향상된 방식 (식 11)

MMD는 커널 선택에 따라 민감할 수 있기 때문에,  
여러 개의 커널을 조합해서 사용합니다:

$$
K = \left\{ k = \sum_{\mu=1}^{n_k} \beta_\mu k_\mu \ \middle| \ \beta_\mu \geq 0, \sum \beta_\mu = 1 \right\}
$$

- $$\beta_\mu$$: 커널의 가중치
- $$k_\mu$$: 다양한 커널 함수

> 커널을 여러 개 조합하면 **더 유연하고 안정적인 정렬이 가능**합니다.

---

## 📚 최종 Feature Matching Loss (식 12)

모델 내부의 **여러 층의 특징**을 정렬하기 위해,  
모든 fully-connected layer에 대해 MMD를 적용합니다:

$$
\mathcal{L}_{FM} = \sum_{i=1}^{N_H} \mathcal{L}_{\text{MMD}, i}^{FT-T}(feat^{FT}_i, feat^T_i)
$$

- $$N_H$$: fully connected layer 수
- $$feat_i$$: $$i$$번째 층에서 나온 특징 벡터

---

## ✅ 이게 왜 중요한가요?

- 가짜 이미지와 진짜 이미지의 **특징 분포를 정렬**하면,
- 모델이 타겟 도메인에서도 **더 잘 분류**할 수 있습니다.
- 결국, **정확도 향상 + 일반화 능력 강화**!

---

## 🔚 요약

| 항목 | 설명 |
|------|------|
| 문제 | 스타일 변환만으로는 도메인 적응이 부족함 |
| 해결 | 가짜 이미지와 진짜 타겟 이미지의 특징을 정렬함 |
| 수단 | MMD (Maximum Mean Discrepancy) |
| 개선 | 여러 커널 조합 + 여러 층에 걸친 정렬 |
| 결과 | 타겟 도메인에서의 성능 향상, 일반화 강화 |

