---
layout: single
title:  "Comprehensive Competition Mechanism in Palmprint Recognition 논문 Review "
categories: Review
tags: [review]
comments: true
author_profile: false
toc: true   
math: true
sidebar:        
    nav: "counts"
---

# 1. 서론 (Introduction)

졸업작품에서 손금인증 시스템을 구축하기로 하였다.\
평소에 생체인식 관련해서 공부해본적이 없기에 생소한 주제였지만 관련 논문을 research 해보았으며\
그 과정에서 현재 손바닥 인식 분야의 SOTA(State-of-the-Art) 모델인 CCNet을 알게 되었고,\
이번 포스팅에서는 이 논문을 자세히 소개하고 리뷰해보고자 한다.\
또한, 이 논문을 통해 얻은 인사이트를 바탕으로\
나의 손바닥 인증 시스템에 어떻게 적용할지에 대한 개인적인 생각과 향후 계획도 함께 정리할 예정이다.\
이어지는 포스팅에서는 직접 설계한 실험 아이디어와 결과까지 공유할 계획이다.

최근 생체 인증 기술 중 손바닥 인식(Palmprint Recognition)이 주목받고 있다.\
손바닥에는 주름, 주선(principal lines), 피부의 미세한 질감(texture) 등 독특하고 안정적인 특징이 존재해, 보안성과 신뢰성이 높은 인증 수단으로 평가받는다.

하지만 기존 손바닥 인식 방법들은 주로 채널(Channel) 차원의 정보에만 집중해왔다.\
이는 손바닥 이미지가 가진 공간적 관계(Spatial Information) 나 다양한 질감 수준(Multi-Order Texture) 을 충분히 활용하지 못하는 한계가 있다.\
결국 조명 변화, 장치 차이, 새로운 사용자 환경에 대한 대응력이 떨어지는 문제가 발생한다.

이 문제를 해결하기 위해, 본 논문에서는\
Comprehensive Competition Mechanism (CCM) 을 새롭게 제안한다.

채널 경쟁(Channel Competition) 뿐만 아니라,\
공간 경쟁(Spatial Competition),\
다중 차수 경쟁(Multi-Order Competition) 까지 함께 고려하여,\
손바닥의 특징을 더 풍부하고 입체적으로 추출할 수 있도록 설계한 것이다.\
이를 적용한 새로운 손바닥 인식 네트워크인 CCNet은\
PolyU, Tongji, IITD 등 공개 손바닥 데이터셋에서 탁월한 성능을 입증했으며,\
특히 EER(Equal Error Rate)을 기존 방법에 비해 획기적으로 낮추는 성과를 보였다.\

이 리뷰에서는 CCNet의 핵심 아이디어, 실험 결과, 한계점, 그리고 향후 발전 가능성까지 자세히 분석해본다.


# 2. CCNet의 핵심 아이디어

CCNet은 손바닥 이미지에서 더 정교하고 풍부한 특징을 추출하기 위해,\
기존 방법들과 차별화된 "포괄적 경쟁 메커니즘(Comprehensive Competition Mechanism, CCM)" 을 새롭게 도입했다.\

기존 손바닥 인식 방법들은 대부분 채널 간 경쟁(Channel Competition) 만 고려했지만,\
CCNet은 이를 넘어,\
채널 경쟁(Channel Competition),\
공간 경쟁(Spatial Competition),\
다중 차수 경쟁(Multi-Order Competition)을 함께 고려하여, 손바닥의 구조적, 질감을 풍부하게 뽑아내어\
선명한 주름(Principal lines) 뿐만 아니라,\
미세한 질감(Texture details) 과\
패턴 간의 구조적 관계(Spatial relationships) 까지도 동시에 학습할 수 있다고한다.

근데 채널 경쟁, 공간 경쟁, 다중 차수 경쟁이 뭔지 생소할 수도 있는 분들을 위해 다음과 같은 개념을 아래에서\
추가로 자세하게 살펴보기로 하자.


## 채널 경쟁 (Channel Competition)
기존 신경망들은 서로 다른 채널(feature map)들 사이의 중요도를 조정하는 데 초점을 맞춰왔다.\
채널 간 경쟁은 각 채널이 입력 특징 중 어느 부분을 더 강조할지를 조정하는 역할을 한다.

그러면 궁금할 것이다. 손금인식에서 왜 채널 경쟁이 필요할까?

### (1) 왜 채널 경쟁이 필요한가?
CNN(Convolutional Neural Network)에서는\
입력 이미지가 여러 개의 채널(feature map) 로 변환된다.\
각각의 채널은 이미지에서 특정한 패턴이나 특징을 포착하려고 만들어진다.\
쉽게 설명하자면 예를 들어, 채널 1은 수평 방향 선을 잘 보고, 채널 2는 곡선 패턴을 잘 보고, 채널 3은 밝기 변화를 민감하게 감지할 수도 있다. 

어떤 손바닥은 굵은 주름(Principal Lines) 이 훨씬 뚜렷하고,\
어떤 손바닥은 상대적으로 피부결(Texture Details) 이 더 복잡하고 특징적일 수 있다.

사람마다 중요한 특징이 다를 수 있고,\
조명, 촬영 환경에 따라 어떤 특징이 더 잘 드러날지도 달라진다.

그래서 CCNet에서는,

입력된 손바닥 이미지를 보고,\
"이 손바닥에서는 어떤 채널(특징 종류)이 가장 중요한가?"를 판단해서,\
중요한 채널은 더 강조하고, 덜 중요한 채널은 억제하는 방식으로 학습을 진행한다.


즉,\
모든 채널이 항상 중요한 건 아니다.\
어떤 채널은 "지금 보고 있는 손바닥"에 별로 도움이 안 될 수도 있다.\
반대로 어떤 채널은 "지금 이 손바닥 인식"에 아주 중요할 수도 있다.

그래서 "지금 중요한 채널은 더 강조하고, 덜 중요한 채널은 무시하거나 약화시키자"\
이런 아이디어가 바로 채널 경쟁(Channel Competition) 이다.

### (2) 채널 경쟁은 어떻게 구현하나?

일반적인 과정으로\
Feature Map이 여러 개 (ex. 128채널) 만들어진다.\
이 Feature Map들을 각각 요약(통합)해서, 채널별 대표 값을 만든다.\
대표적인 방법: Global Average Pooling\
(각 채널의 평균적인 "활성도"를 구한다.)

이 대표 값들을 작은 신경망(FC Layer)을 통과시켜서,\
각 채널이 얼마나 중요한지 스코어를 예측한다.\
그 중요도 스코어를 원래 Feature Map에 곱해서(Scaling)\
중요한 채널은 더 크게,\
덜 중요한 채널은 작게 만들어버린다.

구조적으로 보면\
[Feature Maps] → [Global Avg Pooling] → [FC Layer] → [채널별 중요도 스코어] → [곱하기] → [강조된 Feature Maps]

### (3) 채널 경쟁을 하면 어떤 효과가 있을까?

특징 추출 정밀도가 올라간다.\
덜 중요한 특징에 리소스를 낭비하지 않고,\
정말 중요한 특징을 더 강하게 보게 된다.\
잡음(Noise)에 강해진다.\
쓸모없는 채널을 약화시켜서, 의미 없는 특징에 흔들리지 않는다.\
학습 효율이 좋아진다.\
중요한 채널에 더 집중하니까, 학습이 더 빠르고, 최적화가 잘 된다.

### (4) CCNet 논문에서의 채널 경쟁은?

CCNet에서는\
Comprehensive Competition Mechanism (CCM) 안에서,\
가장 첫 번째 단계로 채널 간 경쟁을 적용했다.

서로 다른 채널 사이에 누가 더 중요한지 판단하고\
중요한 채널에 더 많은 비중(가중치)을 주도록 학습하였다.\
이 과정을 통해, 손바닥 이미지 안에서 굵은 주름, 미세한 질감 등을 더 정확하게 뽑아낸다.

## 공간 경쟁(Spatial Competition)

### (1) 왜 공간 경쟁이 필요한가?

CNN(합성곱 신경망)은 기본적으로 공간 정보(Spatial Information) 를 가진 이미지를 처리한다.

이미지는 가로(W) × 세로(H) 로 구성되어 있다.\
CNN은 이 이미지에 필터(커널)를 슬라이딩하면서 특징을 추출한다.\
그런데 문제는,\
이미지 내 모든 위치가 똑같이 중요한 게 아니다.

사람이 사물을 인식할 때는, 모든 부분을 똑같이 주목하지 않는다.

핸드폰을 볼 때를 생각해보자.

우리는 화면의 빈 검은 부분만을 보고 "이건 핸드폰이다"라고 인식하지 않는다.\
대신,

핸드폰의 네모난 경계선,\
액정 화면,\
버튼과 같은\
의미 있는 위치들을 자연스럽게 더 주목한다.\
이처럼 우리의 뇌는 사물 안에서도\
**"어디를 봐야 중요한 정보가 있는지"**를 본능적으로 판단하고,\
중요한 위치에 더 많은 인지 자원을 쏟는다.

딥러닝 모델에서도 마찬가지다.\
특히 손바닥 이미지처럼,

주름이 복잡하게 얽힌 부분,\
피부결이 두드러지는 부분과\
아무 무늬 없는 평평한 부분이 공존하는 경우,\
모든 위치를 똑같이 학습하는 것은 비효율적이다.

공간 경쟁(Spatial Competition) 은

"Feature Map 내에서 중요한 위치를 강조하고, 덜 중요한 위치는 억제하는 메커니즘"이다.\
이를 통해 네트워크는 손바닥 이미지 안에서도\
주름이 뚜렷하거나, 피부 결이 복잡한 중요한 부위에 더 집중해서 학습할 수 있게 된다.

손바닥 이미지에서

어떤 위치는 뚜렷한 주름(Principal Line)이 있고,\
어떤 위치는 단순히 매끈한 피부(Flat Texture)만 있다.\
그런데 모든 위치를 똑같이 취급하면,

특징이 많은 곳(주름, 패턴 등)을 제대로 살리지 못하고\
특징이 없는 곳까지 쓸데없이 학습하려고 한다.\
결국 모델이 비효율적으로 학습된다.

그래서 나온 생각이 뭐냐면?\
"공간적인 위치 간에도 중요도를 계산해서, 더 중요한 위치는 강조하고, 덜 중요한 위치는 억제하자!"\
이게 바로 공간 경쟁(Spatial Competition) 이다.

### (2) 공간 경쟁은 어떻게 구현할까?

Feature Map (크기: H×W×C)이 입력으로 들어온다.\
이 Feature Map에서\
각 위치(H×W) 마다\
"이 위치가 중요한가?" 를 판단하는 스코어를 만든다.\
(예: 32×32 Feature Map이면, 32×32개의 스코어)\
이 중요도 스코어를 원래 Feature Map에 곱해준다.\
중요도가 높은 위치는 강조된다 (값이 커진다).\
중요도가 낮은 위치는 약해진다 (값이 작아진다).

[Feature Map] → [공간 중요도 추출 (H×W 스코어)] → [곱하기] → [강조된 Feature Map]

쉽게 말하면 "이미지 안에서 진짜 중요한 부분(주름, 무늬)을 더 선명하게 보고, 쓸모없는 부분(밋밋한 피부)은 약화시키는 것."

### (3) 공간 경쟁을 적용하면 어떤 효과가 있나?

지역적으로 특징이 풍부한 부분(주름, 패턴) 은 네트워크가 더 강하게 학습하게 된다.\
정보가 적은 부분(평평한 피부 등) 은 학습량이 줄어든다.\
결과적으로\
모델의 특징 추출 능력이 향상되고,\
노이즈에 강해지며,\
학습 효율이 대폭 좋아진다.\
 특히 손바닥 인식처럼, "부위별로 특징 밀도가 다를 때" 엄청난 효과를 볼 수 있다.

## 다중 차수 경쟁(Multi-Order Competition)

### (1) 다중 차수(Multi-Order)란 무엇인가?

**다중 차수(Multi-Order)**란,\
**서로 다른 해상도(Level of Detail)**를 가지는 특징(feature)을 동시에 추출하고 학습하는 방법론이다.

손바닥 인식처럼 복잡한 패턴이 섞여 있는 문제에서는

1차 특징 (First-Order Feature): 선, 모서리, 윤곽 등 큰 구조\
2차 특징 (Second-Order Feature): 피부결, 미세 패턴 등 세부 구조\
이 둘을 모두 이해해야 전체적인 인식이 가능하다.

다중 차수는 "특징 복잡도(Feature Complexity) 또는 스케일(Scale)에 따른 차이"를 의미하며,\
미분 차수(derivative order)와는 무관하다.

### (2) 다중 차수는 왜 필요한가?

손바닥 이미지는

뚜렷한 굵은 주름(Principal Line)과\
미세한 질감(Fine Texture)이\
서로 다른 해상도에서 존재한다.\
그런데 전통적인 CNN은

하나의 커널 크기,\
하나의 스케일\
만을 기반으로 특징을 추출한다.\
결과

큰 구조만 보거나 (1차만 보는 경우)\
세밀한 질감만 보거나 (2차만 보는 경우)\
어느 한쪽에만 치우치게 된다 -> 전체 손바닥을 온전히 이해할 수 없다.

### (3) 기존 방식의 한계

Single-Scale Feature Learning\
대부분의 CNN은 고정된 필터 크기와 고정된 stride를 사용해, 한 종류의 해상도만 처리한다.\
Spatial Pyramid Pooling (SPP) 같은 기법은\
여러 크기 feature를 추출하긴 하지만,\
단순한 concat(병합) 으로 끝나는 경우가 많다. (스케일 간 중요도 차이를 고려하지 않음)\
결국, 다양한 특징 차수의 상대적 중요도(Importance)를 학습하지 못한다.

### (4) 네트워크 관점에서의 구현

A. Feature Extraction

1차 특징 추출기 (First-Order Extractor)\
큰 receptive field를 가지는 필터 사용\
강한 smoothing or downsampling을 통해 큰 패턴만 강조\
(ex. 큰 커널 사이즈, 강한 pooling)

2차 특징 추출기 (Second-Order Extractor)\
작은 receptive field를 가지는 필터 사용\
fine-grained detail을 살리는 방향\
(ex. 작은 커널, 약한 pooling)\
B. 경쟁 메커니즘 (Competition Module)

두 특징(1차, 2차) 각각에 대해 중요도(Weight)를 예측\
Softmax나 Sigmoid 같은 방식으로\
각 특징의 상대적 중요도를 계산\
중요도에 따라 Feature들을 조합 (Weighted Sum)

C. Feature Fusion

$$F_{\text{final}} = \alpha \times F_{\text{first-order}} + (1-\alpha) \times F_{\text{second-order}}$$

여기서 α는 학습 가능한 파라미터 또는 attention mechanism에 의해 동적으로 결정된다.

이제 CCNet을 이해하기 위한 기본적인 개념은 배웠다.
논문으로 들어가보자.

# 3. 관련연구

기존 크기 응답(magnitude-based) 필터링 방법(PalmCode 등)은\
Gabor, Gaussian, Radon 등 손수 설계한 필터로 주름·질감 특징 추출\
회전·변위에 민감하고, 조명·디바이스 변화에 약함\
이런 한계를 극복하기 위해 나온 것이 경쟁(competition) 메커니즘\
여러 방향·채널의 응답을 서로 비교(“누가 더 강한가?”)\
최강 응답만 골라 코드화 → “어느 방향이 최고인가” 정보로 활용

| 기법                  | 핵심 아이디어                                                                                      | 장점                      | 단점                                    |
| ------------------- | -------------------------------------------------------------------------------------------- | ----------------------- | ------------------------------------- |
| **PalmCode**    | 6개 Gabor 방향 필터 중 “가장 큰 응답”의 인덱스(3비트)를 이진화 템플릿에 저장                                            | 속도·저장 공간 효율 높음          | 회전·변위·조명 변화에 민감                       |
| **RLOC**        | Gabor 대신 “직선 검출(line detection)” 기반 오리엔테이션 코드 적용 → 라인 주름에 더 강건                               | 접촉식·비접촉식 모두 견고          | 필터 설계 여전히 수작업, 채널 정보만 사용              |
| **HOC**        | “절반 방향(0\~90°)”만 쓰는 Gabor 경쟁 → 방향 대칭성 줄여 회전 민감도 약간 완화                                        | 단순·빠름                   | 정보량(6방향) 감소로 표현력↓                     |
| **DOC**        | 상위 2개 응답 방향을 순서쌍(binary pair)으로 코드화 → 단일 winner보다 더 많은 방향 정보 보존                              | 풍부한 방향 정보 확보            | 더 복잡한 코드, 여전히 1차원(채널) 경쟁만             |
| **DCC / DRCC**  | 1) winner 방향 + 이웃 방향과의 **순서(ordinal) 관계** 코딩<br>2) DRCC는 이 순서 차이에 가중치 추가                     | 방향 관계까지 표현, 판별력↑        | 고차(2차 이상)·공간 정보 무시, hand-crafted 필터依存 |
| **CompNet**    | CNN feature map **채널별 softmax 경쟁(Soft Competition Code)**<br>→ 단순 응답 인덱스가 아니라 “채널별 순위 점수” 학습 | 딥피처 이용, soft scoring 도입 | 여전히 채널 차원 경쟁만, 공간·고차 질감 무시            |

## 기법들의 공통 한계

Hand-crafted 필터 의존\
필터 방향·크기 설계를 사람이 직접→ 새로운 환경엔 다시 튜닝 필요\
1차원(채널) 경쟁만 수행\
“어느 채널(방향)이 최고인가”만 확인 → 픽셀 위치(공간 위치)와 고차 질감(2차 이하 특징) 정보 유실\
일반화·강건성 부족\
조명·디바이스·사용자 배경 변화에 제대로 대응 못한다/

## 왜 CCNet의 CCM이 필요한가?

위 모든 기법들이 “채널 경쟁만”  또는 “1차 질감만” 바라보는 데 그쳤다면,\
CCNet(CCM) 은 이 위에 공간 경쟁(Spatial Competition) 과 다중 차수 경쟁(Multi-Order Competition) 을 더해\
채널(어느 방향?), 2. 공간(어디 위치?), 3. 차수(얼마나 고차 질감?)\
세 축을 동시에 “경쟁”시켜 훨씬 더 풍성하고 견고한 특징 표현을 목표로 합니다.

# 4. CCNet의 방법론

기존 손바닥 인식 방법들은 대부분 채널 간 경쟁(Channel Competition)만 고려하고, 공간 정보(Spatial Information)와 다중 차수 텍스처(Multi-Order Texture Features)는 무시하는 경향이 있었다. 이를 해결하기 위해 CCNet은 "포괄적 경쟁 메커니즘 (Comprehensive Competition Mechanism, CCM)"을 도입하여, 채널, 공간, 다중 차수 경쟁을 동시에 고려하는 새로운 접근법을 제안했다.

## Learnable Gabor Filters

* Gabor 필터는 손바닥 텍스처 방향을 효과적으로 추출할 수 있는 강력한 도구이다.
* 기존 방식은 수작업으로 하이퍼파라미터를 설정했지만, CCNet은 학습 가능한(Learnable) Gabor 필터를 사용하여 학습 중 최적의 하이퍼파라미터를 자동으로 찾는다. 
* 다양한 크기(Multi-Scale)로 텍스처를 추출

  * Tiny Scale: 7×7
  * Middle Scale: 17×17
  * Large Scale: 35×35
* 각 스케일마다 2개의 Gabor 레이어를 사용하여, 1차, 2차 텍스처 특징을 동시에 추출한다.

```markdown
### Learnable Gabor Filters 구조
- Adaptive learning of Gabor filter parameters.
- Multi-scale extraction: 7×7, 17×17, 35×35.
- Two learnable Gabor layers per branch for multi-order texture.
```

> **왜 학습 가능한 Gabor 필터를 사용할까?** \
> 기존 손바닥 인식에서는 사람이 Gabor 필터의 방향성, 주파수, 가우시안 분산 같은 하이퍼파라미터를 수작업으로 설정했지만, 데이터의 다양성과 변동성(조명, 촬영기기, 피부 상태 등)을 반영하는 데 한계가 있었다.\
> CCNet은 Gabor 필터의 파라미터를 학습 가능한 형태로 변형하여, 데이터에 최적화된 텍스처 특징을 스스로 찾아내도록 한다.\
> 이를 통해 수작업 설정보다 더 높은 구별력(discriminative power)을 확보하고, 다양한 환경에서도 강건한 손바닥 인식이 가능해진다.


### Competition Mechanism

CCNet은 채널 경쟁과 공간 경쟁을 함께 수행하여 더 풍부한 특징을 추출한다.

![image](/images/first/feature.png)

* **Channel Competition**: 어떤 채널이 가장 중요한지를 Softmax를 통해 계산
* **Spatial Competition**: X축과 Y축 방향으로 Softmax를 적용하여, 최적의 반응 위치를 찾아낸다

$$
F_c = Softmax_c(F_{in}), \quad F_x = Softmax_x(F_{in}), \quad F_y = Softmax_y(F_{in})
$$

여기서

* $$F_c$$: 채널 경쟁 결과
* $$F_x$$, $$F_y$$: X축, Y축 공간 경쟁 결과

**설명**:

* 채널 경쟁은 텍스처 방향을 식별하고,
* 공간 경쟁은 최적 반응 지점을 찾아낸다.

### Feature Fusion & Enhancement

채널 경쟁과 공간 경쟁의 결과를 가중합하여 최종 특징을 얻는다.

수식:

$$
F_{out} = w_c \times F_c + w_s \times (F_x + F_y)
$$

* $$w_c = 0.8$$, $$w_s = 0.1$$ 로 설정된다.

추가적으로, **SE(Squeeze-and-Excitation) Layer**를 통해:

* 채널별로 attention을 계산하여 가장 구별력 있는 특징을 강조한다.

```markdown
### Feature Fusion 과정 요약
- Weighted Sum: Channel vs Spatial competition 결과 결합
- SE Layer: Channel별 주목(attention) 가중치 계산
```

### Overall Workflow

![image](/images/first/11.png)

**Fig. 1 설명**:
- **입력**: 손바닥 이미지
- **Three-Scale Branches**:
  - **Tiny-Scale Branch** (작은 스케일): 7×7 크기의 Gabor 필터 사용
  - **Middle-Scale Branch** (중간 스케일): 17×17 크기의 Gabor 필터 사용
  - **Large-Scale Branch** (큰 스케일): 35×35 크기의 Gabor 필터 사용
- 각 Branch마다 두 개의 **Learnable Gabor Layer**를 통과하며 1차, 2차 텍스처 특징을 추출
- 각 Gabor Layer 뒤에는 **Comp Block**이 붙는다
  - Comp Block은 채널 경쟁, 공간 경쟁을 수행하고
  - 채널 경쟁은 orientation(방향성)을, 공간 경쟁은 최적 반응 위치를 찾는다
- 각 Branch에서 나온 특징들은 **Concatenation** 연산으로 통합된다
- 통합된 특징은 **Fully Connected Layer**를 통과하여 최종 **Feature Vector**로 변환된다

**Comp Block 내부 구조**:
- 입력 특징에 대해
  - Channel, X축, Y축 방향별 Softmax 수행
  - Weighted Sum 연산을 통해 통합
- 이후 SE Layer를 통과해 채널별 중요한 특징을 강화
- 최종적으로 Max Pooling을 적용하여 Feature Size를 줄임

---

###  핵심 요약

- **Gabor Layer**: 다양한 스케일의 텍스처 정보를 학습 가능하게 추출
- **Comp Block**: 채널과 공간 차원에서 동시에 경쟁 수행
- **SE Layer**: 가장 중요한 채널 강조
- **다중 스케일 + 다중 차수 + 공간 경쟁까지 고려**해서 손바닥 텍스처 특징을 정교하게 뽑아낸다.

**CCNet = 채널 + 공간 + 차수 경쟁을 포괄하는 완전한 손바닥 특징 추출 네트워크**

### 세부 Workflow 흐름

* **입력 이미지**

  * ↓ 학습 가능한 Gabor 필터 적용

    * ↓ 다양한 스케일 및 다중 차수 텍스처 추출

      * ↓ Comp Block (채널 경쟁 + 공간 경쟁)

        * ↓ 가중합 및 SE Layer 통과

          * ↓ 최종 특징 벡터 출력


# 5. 손실함수 (Hybrid Loss Function)

기존 손바닥 인식 네트워크는 Cross-Entropy Loss만 사용해 학습했지만, 이 방법은 정답 분류는 잘하더라도 특징 공간(feature space) 구조를 잘 정리하지 못했다. 이를 해결하기 위해, 본 논문은 Contrastive Loss를 추가하여 Hybrid Loss를 구성하였다.

### Cross-Entropy Loss

* 정답 클래스를 예측하는 확률을 최대화
* 수식:

$$
\mathcal{L}_{ce} = -\frac{1}{N} \sum_{i=1}^{N} \sum_{c=1}^{M} y_{i,c} \log(p_{i,c})
$$

* $$N$$: 전체 샘플 수
* $$M$$: 클래스 수
* $$y_{i,c}$$: 샘플 $$i$$가 클래스 $$c$$에 속하면 1, 아니면 0
* $$p_{i,c}$$: 샘플 $$i$$가 클래스 $$c$$일 확률 (모델 출력)

**특징**:

* Cross-Entropy는 정답 확률을 높이지만, 서로 다른 클래스 간 특징 간격(feature distance)을 최적화하지는 않는다.

### Contrastive Loss

* 같은 클래스끼리는 가깝게, 다른 클래스끼리는 멀게 feature embedding을 유도
* 수식:

$$
\mathcal{L}_{con} = -\sum_{i \in I} \frac{1}{|P(i)|} \sum_{p \in P(i)} \log \left( \frac{ \exp(z_i \cdot z_p / \tau) }{ \sum_{a \in A(i)} \exp(z_i \cdot z_a / \tau) } \right)
$$

* $$I$$: 전체 샘플 인덱스 집합
* $$P(i)$$: 샘플 $$i$$와 같은 레이블을 가진 positive sample 집합
* $$A(i)$$: 샘플 $$i$$를 제외한 모든 샘플 집합
* $$z_i, z_p, z_a$$: 각각 anchor, positive, negative 특징 벡터
* $$\tau$$: Temperature 파라미터 (유사도 조정용)

**특징**:

* Positive (같은 클래스) 끼리는 내적 값 최대화
* Negative (다른 클래스) 끼리는 내적 값 최소화

### 최종 Hybrid Loss

* Cross-Entropy Loss와 Contrastive Loss를 결합하여 최종 Loss를 구성:

$$
\mathcal{L} = w_{ce} \times \mathcal{L}_{ce} + w_{con} \times \mathcal{L}_{con}
$$

* $$w_{ce} = 0.8$$
* $$w_{con} = 0.2$$

**설정 이유**:

* Cross-Entropy는 여전히 주된 분류 기준이므로 더 높은 가중치(0.8)를 부여
* Contrastive Loss는 feature 구조 최적화에 도움을 주므로 보조 가중치(0.2)를 부여

### 요약

| Loss 종류                                 | 기능                      | 역할                        |
| :-------------------------------------- | :---------------------- | :------------------------ |
| Cross-Entropy Loss ($$\mathcal{L}_{ce}$$) | 정답 클래스 예측 확률 최대화        | Classification 정확도 향상     |
| Contrastive Loss ($$\mathcal{L}_{con}$$)  | 같은 클래스는 가깝게, 다른 클래스는 멀게 | Feature embedding 구조 최적화  |
| Hybrid Loss ($$\mathcal{L}$$)             | 둘을 결합 (80% + 20%)       | 분류 정확도 + 특징 공간 최적화 동시에 달성 |

$$\boxed{\text{Hybrid Loss = Classification Accuracy + Feature Embedding Optimization}}$$


## 6 실험적 결과

![image](/images/first/321.png)

wc(채널 경쟁) 비중이 높을수록 EER이 낮고, 성능이 좋다.
ws(공간 경쟁) 비중이 너무 커지면 EER이 급격히 나빠진다.
즉, "채널 경쟁이 주가 되어야 하고, 공간 경쟁은 적절히 보조 역할"로 들어가야 최적 성능을 낼 수 있다는 뜻.
파란 점선(baseline, 채널 경쟁만 썼을 때 성능)보다도 wc를 0.9~0.6으로 크게 잡으면 성능이 더 좋아진다.


![image](/images/first/111.png)

우리가 제안한 방법을 Cross-ID와 Cross-Device 설정 모두에서 테스트했다.
결과는 표 X에 제시되어 있다.

이 논문에서 CCNet의 Cross-ID 성능은 그리 뛰어나지 않았다.
그 원인은 네트워크가 훈련 데이터에 너무 과적합되고,
일반화 능력을 충분히 고려하지 못했기 때문일 수 있다고 말한다.
또한,

현재 사용하는 손실 함수는 알려진 ID에 최적화된 특징 공간을 만드는 데 초점을 맞췄으며,
적응(adaptation) 손실이 없어,
네트워크의 일반화 성능을 높이는 데에는 부족했다 판단했다.
우리는 이 문제를 흥미로운 연구 주제로 인식하고 있으며,
향후 연구에서 CCNet의 Cross-ID 성능 향상 방법을 탐색할 계획이아고한다.

실제로 내가 데이터를 학습해본 결과라 배경과 각도가 좀만 달라지면 인식하기가 매우 힘들었다.\
(나는 PolyU 데이터셋을 사용하여 학습을 하였고 학습 후 사람 당 10장의 사진으로 평균 임베딩 벡터 저장 후 판별 시도하였다)

## 7. 개인적 생각

기존 CCNet은 RGB 이미지 기반으로 손바닥 인식을 수행하여 좋은 성능을 보였지만,
배경 변화나 촬영 각도 차이에 매우 민감하여 실제 적용에는 한계가 있었다.

이를 극복하기 위해,
OAK-D 카메라를 활용해 깊이(Depth) 정보를 추가로 사용하고,
3D 형태 정보를 학습에 포함시켜 모델의 일반화 능력을 강화하고자 한다.

깊이 정보는 손바닥의 표면 굴곡, 주름, 골(溝) 등의 구조를 반영할 수 있어,
단순 RGB 패턴 기반 인식보다 각도 변화, 조명 변화, 배경 변화에 훨씬 강건한 특징을 제공할 수 있을 거라고 기대중이다.

손실 함수 설계가 일반화보다는 훈련 세트 최적화에 집중되어 있었다.
CCNet은 현재 ID들 간의 구분(intra-set classification)에만 집중하는 손실 함수를 썼다.
새로운 ID(Cross-ID)나 다른 도메인(Cross-Device) 상황에 대해 적응(adaptation)하도록 설계되지 않았다.
적응 손실(adaptation loss)이 없었다.
손바닥 특징을 도메인/ID 독립적으로 일반화(generalize) 시키는 기법을 넣지 않았기 때문에,
훈련된 ID를 벗어나면 성능이 급격히 떨어진다고 분석했다.

그래서 손실함수쪽도 실생활에서 적응력이 강한 것을 실험해볼 필요가 있을 거 같다.
또한, OAK-D 카메라를 통해 적용하면 오픈셋 데이터랑 환경이 다르기에 fine-tununig도 필수적일 거 같다.

