---
layout: single
title:  "CNN 공부"
categories: ML
tags: [Pytorch, CNN]
comments: true
author_profile: false
toc: true   
sidebar:    
    nav: "docs"
---

# AI Research Engineer를 위한 CNN 이해하기


## Pytorch - Convolution 구현

아래는 Pytorch로 Convolution 간단하게 구현한 코드입니다.

```python   
import torch
import torch.nn as nn
import numpy as np
from PIL import Image

class Conv2DGray(nn.Module):
    def __init__(self, kernel):
        super(Conv2DGray, self).__init__()
        self.conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=kernel.shape, bias=False)
        with torch.no_grad():
            self.conv.weight = nn.Parameter(torch.tensor(kernel, dtype=torch.float32).unsqueeze(0).unsqueeze(0))

    def forward(self, image: Image.Image):
        image_tensor = self.pre_proc(image)
        output_tensor = self.conv(image_tensor)
        output_image = self.post_proc(output_tensor)
        return output_image
    
    def pre_proc(self, gray_image: Image.Image) -> torch.Tensor:
        image_np = np.array(gray_image).astype(np.float32)
        image_tensor = torch.tensor(image_np).unsqueeze(0).unsqueeze(0)
        return image_tensor

    def post_proc(self, image_tensor: torch.Tensor) -> Image.Image:
        output_image = image_tensor.squeeze(0).squeeze(0).detach().numpy()
        return Image.fromarray(output_image.astype(np.uint8))
```


### 동작 순서
**초기화 (__init__)**<br><br>
사용자 정의 2D 커널(필터)를 받아 Conv2D 레이어의 가중치로 등록합니다.<br>
torch.no_grad() 블록을 사용해 학습되지 않는 고정된 필터로 설정합니다.<br><br>
**전처리** (pre_proc)<br><br>
PIL 이미지를 NumPy 배열로 변환하고,<br>
PyTorch 텐서(4D: batch, channel, height, width)로 변환합니다.<br><br>
순전파 (forward)<br><br>
입력 이미지를 컨볼루션 레이어에 전달하고,<br>
그 결과를 후처리하여 PIL 이미지로 반환합니다.<br><br>

**후처리** (post_proc)<br><br>
텐서를 다시 NumPy 배열로 변환하고,<br>
8비트 정수형 이미지로 변환해 반환합니다.<br>

### <상세분석> 1. nn.Module 상속
```python   
class Conv2DGray(nn.Module)
```
파이썬 클래스 Conv2DGray를 정의하고, PyTorch 신경망 모듈(nn.Module)을 상속받아
"특정 연산(여기서는 Conv2D)을 수행하는 커스텀 레이어"를 만든 것.
이렇게 하면 PyTorch 모델로 등록되어, 학습(가중치 업데이트), 추론(순전파), GPU 연산 등을 쉽게 처리할 수 있다.


### <상세분석> 2. 초기화 (__init__)
```python   
 def __init__(self, kernel):
```  

메서드 이름: __init__ (생성자)<br>
매개변수: kernel<br>
2D 형태의 커널(필터)을 받아서, 컨볼루션 레이어의 가중치로 설정할 예정.<br>
이 클래스(Conv2DGray)가 생성될 때 자동으로 호출돼서, 내부 변수를 초기화하는 과정.<br>
즉, Conv2DGray(kernel)처럼 객체를 생성하면, 커널을 전달받아 초기 세팅을 하게 됨.

```python   
super(Conv2DGray, self).__init__()
```
부모 클래스: nn.Module
Conv2DGray는 nn.Module을 상속받았기 때문에, 부모 클래스의 생성자를 명시적으로 불러줘야 함.
이유: PyTorch 내부적으로 nn.Module이 가지고 있는 가중치 관리, 그래디언트 추적 등 기능을 올바르게 초기화해주기 위해서.
"부모(nn.Module)를 Conv2DGray 객체 관점에서 초기화해줘!"라는 뜻이야.

```python   
self.conv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=kernel.shape, bias=False)
```
이 줄은 PyTorch의 2D 컨볼루션 레이어를 초기화하는 코드야.


in_channels=1

입력 채널이 1개라는 뜻 → 그레이스케일 이미지를 염두에 둔 설정.


out_channels=1:

출력 채널도 1 → 결과도 **1채널(그레이스케일)**로 출력.

kernel_size=kernel.shape:

kernel이 2D 배열(예: 3x3, 5x5 등)일 것이므로, 그 가로×세로 크기를 그대로 사용.

bias=False:

편향(bias)을 사용하지 않음.

주로 엣지 검출 같은 고정된 필터에는 편향이 필요 없어서 빼는 경우가 많음.

> 1. 입력 채널(Input Channels)
>
>그레이스케일 이미지: 채널=1 (검은색~흰색 농도 정보만 있음)

>컬러(RGB) 이미지: 채널=3 (Red, Green, Blue 3가지 색상 채널)

>추가 채널: 알파 채널(RGBA)이 있으면 채널이 4가 될 수도 있고,

>Depth 정보나 다른 센서 데이터가 붙으면 채널이 더 커질 수도 있어.

>결국 입력 채널은 **"이 레이어가 한 번에 처리해야 할 데이터 깊이"**라고 할 수 있어.

>

> 2. 출력 채널(Output Channels)
>
>합성곱 레이어는 **필터(커널)**를 여러 개 사용해.

>각 필터는 입력을 받아 새로운 **특징맵(feature map)**을 만든다고 볼 수 있어.

>필터 개수 = 출력 채널 수라고 생각하면 돼.

```python   
self.conv.weight = nn.Parameter(torch.tensor(kernel, dtype=torch.float32).unsqueeze(0).unsqueeze(0))
```

이 줄이 실질적으로 "사용자 정의 커널"을 Conv 레이어의 가중치로 직접 넣어주는 핵심이야.

torch.tensor(kernel, dtype=torch.float32)

-> 넘파이 배열(kernel)을 PyTorch 텐서로 변환.

dtype=float32로 설정해, GPU/CPU 계산에서 표준으로 많이 사용하는 부동소수 형태.

.unsqueeze(0).unsqueeze(0)

텐서의 차원을 2번 확장.

보통 kernel.shape == (KH, KW) (예: 3x3)일 텐데,

첫 번째 unsqueeze(0) → (1, KH, KW) (필터 개수 차원)

두 번째 unsqueeze(0) → (1, 1, KH, KW) (입력 채널 차원까지)

Conv2d 가중치는 (out_channels, in_channels, kernel_height, kernel_width) 형태로 되어 있어야 해.

여기서는 **out_channels=1, in_channels=1**이므로, 결국 (1, 1, KH, KW)가 맞는 형태가 되는 거지.

nn.Parameter(...)

이렇게 만든 텐서를 **PyTorch가 학습/추적할 수 있는 "파라미터"**로 등록.

하지만 with torch.no_grad(): 블록 안이니까, 실제 학습(optimizer 업데이트)은 되지 않는 고정 필터가 될 거야.

self.conv.weight = ...

최종적으로 Conv2D 레이어의 weight에 우리가 만든 텐서를 대입.

그 결과, 합성곱을 수행할 때 PyTorch가 이 커널을 사용해 이미지에 연산을 적용하게 됨.




